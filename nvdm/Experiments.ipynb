{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "# Current model gives RuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasCreate(handle)`\n",
    "# during training when running on GPU. Disable for now.\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import data_handling as data\n",
    "import preprocess as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Original data\n",
    "# DATA_RAW_PATH = \"./data/bds_1.txt\"\n",
    "# IDs, BDs = data.load_raw(DATA_RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data that has already been preprocessed\n",
    "# Generated by applying pp.preprocess_text() to each BD,\n",
    "# then saved to a TSV\n",
    "DATA_CLEAN_PATH = \"./data/bds_1_clean.txt\"\n",
    "IDs_raw, BDs_raw = data.load_raw(DATA_CLEAN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 2034\n"
     ]
    }
   ],
   "source": [
    "# Some entries have empty BDs, so filter those out\n",
    "IDs = []\n",
    "BDs = []\n",
    "for iid, bd in zip(IDs_raw, BDs_raw):\n",
    "    if len(bd) > 0:\n",
    "        IDs.append(iid)\n",
    "        BDs.append(bd)\n",
    "\n",
    "print(len(IDs), len(BDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following PyTorch's tutorial for data setup.\n",
    "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build frequency table\n",
    "# (cleaned data joins tokens by space)\n",
    "counter = Counter()\n",
    "for desc in BDs:\n",
    "    counter.update(desc.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70770\n"
     ]
    }
   ],
   "source": [
    "# PyTorch torchtext vocabulary converts tokens to indices and vice versa.\n",
    "# Also has an '<unk>' for OOV words (might be useful later).\n",
    "vocab = Vocab(counter,\n",
    "              max_size=None,\n",
    "              min_freq=1,\n",
    "              specials=['<unk>'])\n",
    "print(len(vocab))\n",
    "# actual is 70770 without max_size restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "52243 52243 commercial\n",
      "[52243, 1410, 76, 4060]\n"
     ]
    }
   ],
   "source": [
    "# Example usage: unknown word, convert token to int ID, convert a whole list of tokens to IDs.\n",
    "print(vocab.stoi[\"thisworddoesntexist\"], vocab.unk_index)\n",
    "print(vocab[\"commercial\"], vocab.stoi[\"commercial\"], vocab.itos[vocab[\"commercial\"]])\n",
    "print(vocab.lookup_indices([\"commercial\", \"fact\", \"data\", \"tech\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDDataset(Dataset):\n",
    "    \"\"\" Very simple dataset object. Stores all the passages.\n",
    "    \n",
    "    This is just for compatibility with PyTorch DataLoader.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Preprocessing\" function\n",
    "def text_pipeline(text):\n",
    "    return [vocab[token] for token in text.split(\" \")]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    \"\"\" Convert a batch of text (each a list of tokens) into appropriate torch tensors.\n",
    "    \n",
    "    Modification of https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html.\n",
    "    We don't need labels.\n",
    "    \"\"\"\n",
    "    # Offsets tells the model (which will use EmbeddingBag) where each text starts.\n",
    "    text_list, offsets = [], [0]\n",
    "    for _text in batch:\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: try autoencoder models from here:\n",
    "# example https://github.com/shentianxiao/text-autoencoders/blob/master/model.py\n",
    "\n",
    "# The one below includes built-in embeddings that can be trained.\n",
    "\n",
    "# class BasicAutoencoder(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_dim, batch_size):\n",
    "#         super(BasicAutoencoder, self).__init__()\n",
    "#         # EmbeddingBag is basically Embedding but aggregates words (i.e. bag-of-words).\n",
    "#         # See the \"mode\" argument. Quoted from official documentation:\n",
    "#         # with ``mode=\"sum\"`` is equivalent to :class:`~torch.nn.Embedding` followed by ``torch.sum(dim=1)``\n",
    "#         # Also takes an additional \"offsets\" 1D array, which indicates where each sentence starts in the batch.\n",
    "#         # For now we treat a whole document as a sentence (list of tokens).\n",
    "#         self.embedding = nn.EmbeddingBag(\n",
    "#             vocab_size,\n",
    "#             embed_dim,\n",
    "#             sparse=False, # optimizer complains when sparse=True\n",
    "#             mode=\"mean\", # can be sum, mean or max (defaults to mean)\n",
    "#         )\n",
    "        \n",
    "#         self.batch_size = batch_size\n",
    "#         hidden_dim = 64\n",
    "        \n",
    "#         # Very simple encoder/decoder at first\n",
    "#         self.encoder = nn.Linear(embed_dim, hidden_dim)\n",
    "#         self.decoder = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "#     def forward(self, text, offsets):\n",
    "#         \"\"\" Takes a batch of texts and a 1D array telling us where each sentence starts. \"\"\"\n",
    "#         out = self.embedding(text, offsets)\n",
    "        \n",
    "#         out = self.encoder(out)\n",
    "#         out = self.decoder(out)\n",
    "\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicAutoencoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim=64):\n",
    "        super(BasicAutoencoder, self).__init__()        \n",
    "        \n",
    "        # Very simple encoder/decoder at first\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(vocab_size, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # Here text is (batch_size, vocab_size) BoW representation.\n",
    "        out = self.encoder(text)\n",
    "        out = self.decoder(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bow(text, vocab_size):\n",
    "    bow = torch.zeros(vocab_size, dtype=torch.float)\n",
    "    bow_counter = Counter(text.tolist())\n",
    "    for k, v in bow_counter.items():\n",
    "        bow[k] = v\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader to iterate over dataset in batches during training/evaluation\n",
    "dataset = BDDataset(BDs)\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7144904136657715\n",
      "5.486662881448865\n",
      "5.222834336571395\n",
      "5.0932224141433835\n",
      "5.0470630610361695\n",
      "5.0302523002028465\n",
      "5.023749152198434\n",
      "5.0210719387978315\n",
      "5.019853452220559\n",
      "5.019221466965973\n",
      "5.018844919279218\n",
      "5.0185893746092916\n",
      "5.018398659303784\n",
      "5.018245497718453\n",
      "5.018116380088031\n",
      "5.0180038549005985\n",
      "5.017904122360051\n",
      "5.01781468745321\n",
      "5.017732351087034\n",
      "5.017656886018813\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 20\n",
    "# embed_size = 300\n",
    "model = BasicAutoencoder(len(vocab), hidden_dim=64).to(device)\n",
    "model.train()\n",
    "\n",
    "# For simplicity\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for idx, (text, offsets) in enumerate(data_loader):\n",
    "\n",
    "        text = text.to(device)\n",
    "        offsets = offsets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Construct BOW representations\n",
    "        # Last batch could be smaller than batch_size #data is not a multiple.\n",
    "        actual_batch_size = offsets.size(0)\n",
    "        bow = torch.zeros((actual_batch_size, len(vocab))).to(device)\n",
    "        for i in range(len(offsets) - 1):\n",
    "            # Extract i^th sentence in the batch and compute BOW\n",
    "            bow[i] = to_bow(text[offsets[i]:offsets[i+1]], len(vocab))\n",
    "\n",
    "        # Predict BOW representation directly\n",
    "        \n",
    "        #\n",
    "        # GPU ERROR HERE\n",
    "        #\n",
    "        bow_pred = model(bow)\n",
    "        \n",
    "        loss = criterion(bow_pred, bow)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Epoch {}, Loss={}\".format(epoch + 1, epoch_loss / len(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the model's output\n",
    "model.eval()\n",
    "\n",
    "# Store the \"hidden representations\" (i.e. encoder output) for all passages\n",
    "# and see if they are meaningful (probably not at this stage because the model is too simple,\n",
    "# not enough data etc, not enough training epochs etc.)\n",
    "hidden_vecs = torch.zeros((len(BDs), 64))\n",
    "with torch.no_grad():\n",
    "    for i, text_raw in enumerate(BDs):\n",
    "        text = torch.tensor(text_pipeline(text_raw), dtype=torch.int64)\n",
    "        bow = to_bow(text, len(vocab))\n",
    "        h = model.encoder(bow.unsqueeze(0))\n",
    "        hidden_vecs[i] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAT:1000697, gener water corpor compani us specialti measur compani oper fundament underli purpos advanc scienc e\n",
      "DISH:1001082, 1 item 1A risk factor 24 item 1B unresolv staff comment 62 item 2 properti 62 item 3 legal proceed 6\n",
      "KTYB:1000232, gener kentucki bancshar compani kentucki us bank hold compani headquart pari kentucki the compani or\n",
      "NVAX:1000694, overview novavax togeth swedish subsidiari novavax AB biotechnolog compani focus discoveri develop c\n",
      "IMH:1000298, impac mortgag hold sometim refer herein compani us maryland corpor incorpor august 1995 includ follo\n",
      "OCC:1000230, overview optic cabl corpor incorpor commonwealth virginia 1983 We headquart 5290 concours drive roan\n",
      "HSIC:1000228, gener henri schein solut compani health care profession power network peopl technolog We believ worl\n",
      "MFIN:1000209, We medallion financi compani financ compani organ delawar corpor includ medallion bank primari oper \n",
      "CLB:1000229, gener core laboratori netherland limit liabil compani We establish 1936 one world lead provid propri\n",
      "SWM:1000623, 1 item 1A risk factor 14 item 1B unresolv staff comment 29 item 2 properti 30 item 3 legal proceed 3\n"
     ]
    }
   ],
   "source": [
    "# Take an example company\n",
    "# Group 1 Automotive, Inc. is an international Fortune 500 automotive retailer.\n",
    "# ID is GPI:1031203\n",
    "GPI_ID = 79\n",
    "target_h = hidden_vecs[GPI_ID]\n",
    "similarity = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "# TODO: compare BOW cosine similarity directly\n",
    "\n",
    "# Show top 10 most similar (based on cosine distance)\n",
    "sims = similarity(target_h.unsqueeze(0), hidden_vecs)\n",
    "idxs = torch.topk(sims, 10, largest=False).indices\n",
    "\n",
    "for idx in idxs:\n",
    "    print(\"{}, {}\".format(IDs[idx], BDs[idx][:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How to iterate through the data batchwise\n",
    "# for idx, (text, offsets) in enumerate(data_loader):\n",
    "    \n",
    "#     # Just have a look at the first item in the first batch.\n",
    "#     start = offsets[0]\n",
    "#     end = offsets[1]\n",
    "#     indices = text[start:end]\n",
    "    \n",
    "#     # Should be equal to the 1st original BD text.\n",
    "#     tmp = \" \".join(vocab.itos[i] for i in indices)\n",
    "#     print(tmp[:500])\n",
    "#     assert tmp == BDs[0]\n",
    "    \n",
    "#     break\n",
    "    \n",
    "#     # TODO: training stuff (model(), loss, backward, optimizer.step etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
